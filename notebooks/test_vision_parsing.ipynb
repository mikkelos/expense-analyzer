{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision\n",
    "from google.cloud import datastore\n",
    "from google.oauth2 import service_account\n",
    "import io\n",
    "import os # for use with setting env variables\n",
    "import re\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' TODO\\n* Discount line logic\\n* Create an interface where the user can manually give an item its category:\\n    * Remember ID and update the category_id, keep other values as the same\\n'"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" TODO\n",
    "* Discount line logic\n",
    "* Create an interface where the user can manually give an item its category:\n",
    "    * Remember ID and update the category_id, keep other values as the same\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = False\n",
    "developing = True\n",
    "key_path = \"/Volumes/GoogleDrive/My Drive/00. My Documents/03. Internt/24. Expense analyzer/config_files/expense-analyzer-260008-0cac2ecd3671.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only used in dev environment\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = key_path\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path,\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERLAPPING_ALLOCATION_THRESHOLD = 0.3\n",
    "\n",
    "# The entity kind in datastore to query to find previous assignments\n",
    "DATASTORE_KIND_CATEGORY_ASSIGNMENT = \"category_item_mapping\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop_and_rotate(path):\n",
    "    # do some magic here\n",
    "    # Identify how scewed the image is\n",
    "    # Rotate it\n",
    "    return 1\n",
    "\n",
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient.from_service_account_json(key_path)\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    \n",
    "    if debug:\n",
    "        print('Texts:')\n",
    "        for text in texts:\n",
    "            print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "            vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                        for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "            print('bounds: {}'.format(','.join(vertices)))\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ### PARSER FOR COOP\n",
    "def article_lines_coop(response):\n",
    "    # Locate the relevant range to extract items\n",
    "    start_y_coordinate = -1     # Determine which point to start extract items\n",
    "    end_y_coordinate = -1       # Determine which point to stop extract items\n",
    "    \n",
    "    receipt_id_and_datetime = \"\"\n",
    "\n",
    "    for text in response.text_annotations:\n",
    "        if len(text.description) > 100:\n",
    "            # Full text, extract the receipt ID and datetime\n",
    "            full_text = text.description\n",
    "\n",
    "            # Start substring from the search term\n",
    "            search_term = \"Salgskvittering\"\n",
    "            start_index = full_text.find(search_term) + len(search_term)\n",
    "\n",
    "            # End the substring at next newline\n",
    "            end_index = start_index + full_text[start_index:].find(\"\\n\")\n",
    "            \n",
    "            # This now contains id, date, time, separated by space\n",
    "            receipt_id_and_datetime = full_text[start_index:end_index].strip()            \n",
    "        elif \"Salgskv\" in text.description:\n",
    "            start_y_coordinate = max(vertex.y for vertex in text.bounding_poly.vertices)\n",
    "            if debug:\n",
    "                print(\"Found starting point at {}, after text {}\".format(start_y_coordinate, text.description))\n",
    "        elif \"Totalt\" in text.description:\n",
    "            end_y_coordinate = min(vertex.y for vertex in text.bounding_poly.vertices)\n",
    "            if debug:\n",
    "                print(\"Found ending point at {}, after text {}\".format(end_y_coordinate, text.description))\n",
    "\n",
    "    # Iterate through all lines, extract only those with item y coordinate larger than start and smaller than end\n",
    "    relevant_items = []\n",
    "    for text in response.text_annotations:\n",
    "        if text.bounding_poly.vertices[0].y > start_y_coordinate and text.bounding_poly.vertices[0].y < end_y_coordinate:\n",
    "            # print(\"Found an item line!: {}\".format(text.description))\n",
    "            relevant_items.append(text)\n",
    "            \n",
    "    return relevant_items, receipt_id_and_datetime\n",
    "\n",
    "\n",
    "# Key = line_number, value = item\n",
    "# Idea: For each bounding box, calculate the mid y coordinate. If this coordinate is inside the bounding box of\n",
    "# another, then these are on the same line.\n",
    "def allocate_lines_coop(items):\n",
    "    \"\"\"\n",
    "    :param items: input is a list of relevant text boxes from Google vision, containing the text found and bounding polygon\n",
    "    :return: returns a dictionary, with all items allocated to a line_id containing all elements on that same line, sorted by their x-coordinates\n",
    "    \"\"\"\n",
    "\n",
    "    receipt_lines = {}\n",
    "    # Key is the line number\n",
    "    # Each value has the format [item]\n",
    "\n",
    "    # Loop over all found text boxes\n",
    "    for item in items:\n",
    "        y_first_coor = item.bounding_poly.vertices[0].y\n",
    "        y_fourth_coor = item.bounding_poly.vertices[3].y\n",
    "        y_mean_coor = (y_first_coor + y_fourth_coor)/2\n",
    "        height = y_fourth_coor - y_first_coor\n",
    "\n",
    "        overlap_up = -1\n",
    "        overlap_down = -1\n",
    "\n",
    "        if len(receipt_lines) == 0:\n",
    "            receipt_lines[0] = []\n",
    "            receipt_lines[0].append(item)\n",
    "\n",
    "        else:\n",
    "            inserted = False\n",
    "\n",
    "            # Loop through all allocated/identified lines\n",
    "            for line in receipt_lines:\n",
    "                # See if item belongs to an existing line\n",
    "                # Compare against y coordinates of first item on line\n",
    "                first_line_item = receipt_lines[line][0]\n",
    "                first_line_item_y1 = first_line_item.bounding_poly.vertices[0].y\n",
    "                first_line_item_y4 = first_line_item.bounding_poly.vertices[3].y\n",
    "\n",
    "\n",
    "                # if mean coordinate is within min and max of line, add it to the line\n",
    "                if first_line_item_y1 <= y_mean_coor <= first_line_item_y4:\n",
    "                    receipt_lines[line].append(item)\n",
    "                    inserted = True\n",
    "                    break\n",
    "\n",
    "                # These are used to calculate overlap between lines\n",
    "                last_line_item = receipt_lines[line][-1]\n",
    "                last_line_item_y1 = last_line_item.bounding_poly.vertices[0].y\n",
    "                last_line_item_y4 = last_line_item.bounding_poly.vertices[3].y\n",
    "\n",
    "                # Calculate a match % against each other line, to see if picture is slightly squished\n",
    "                # Calculate against the item to the far right in the current line\n",
    "                if last_line_item_y1 <= y_first_coor <= last_line_item_y4:\n",
    "                    # Some overlap detected. item is below the line in comparison\n",
    "                    overlap_down = float(last_line_item_y4 - y_first_coor) / height\n",
    "                    if debug:\n",
    "                        print(\"Found {}% overlap under between text {} and {} on line {}\".format(overlap_down, item.description, first_line_item.description, line))\n",
    "\n",
    "                if last_line_item_y1 <= y_fourth_coor <= last_line_item_y4:\n",
    "                    # Some overlap detected. item is above the line in comparison\n",
    "                    overlap_up = float(y_fourth_coor - last_line_item_y1) / height\n",
    "                    if debug:\n",
    "                        print(\"Found {}% overlap over between text {} and {} (first item) on line {}\".format(overlap_up, item.description, first_line_item.description, line))\n",
    "\n",
    "                # If any of the matches are above X%, allocate it to that line\n",
    "                if overlap_down > OVERLAPPING_ALLOCATION_THRESHOLD or overlap_up > OVERLAPPING_ALLOCATION_THRESHOLD:\n",
    "                    receipt_lines[line].append(item)\n",
    "                    inserted = True\n",
    "                    break;\n",
    "\n",
    "            # No match found against previous lines. Create a new line\n",
    "            if not inserted:\n",
    "                new_line_num = len(receipt_lines)\n",
    "                receipt_lines[new_line_num] = []\n",
    "                receipt_lines[new_line_num].append(item)\n",
    "\n",
    "    # Sort each line by the x coordinates\n",
    "    for line in receipt_lines:\n",
    "        receipt_lines[line].sort(key=lambda item: item.bounding_poly.vertices[0].x)\n",
    "\n",
    "    return receipt_lines\n",
    "\n",
    "\n",
    "def lines_to_text(receipt_lines):\n",
    "    \"\"\"\n",
    "    :param receipt_lines: takes a dictionary as input, where the key is a line_id and the value are objects containing the element text and bounding polygon\n",
    "    :return: A list of text strings concatenated for each line, instead of google vision objects\n",
    "    \"\"\"\n",
    "    receipt_text = []\n",
    "    for line in receipt_lines:\n",
    "        text = \"\"\n",
    "        for item in receipt_lines[line]:\n",
    "            text += \" \" + item.description\n",
    "        receipt_text.append(text.lower().strip())\n",
    "    return receipt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_preparation(receipt_text):\n",
    "    \"\"\"\n",
    "    :param receipt_text: list of text strings containing article text and price\n",
    "    :return: a list of multiple tuples, consisting of article type, text and price\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Regex:\n",
    "    \"\\d+\" matches one or more digits\n",
    "    \".\" followed by any charcter\n",
    "    \"\\d+\" one or more digits\n",
    "    \"$\" at the end of the line\n",
    "    \"\"\"\n",
    "    price_pattern = \"(\\d+.\\d+)$\"\n",
    "    discont_pattern = \"\"\n",
    "    articles_querified = []\n",
    "\n",
    "    for article in receipt_text:\n",
    "        if debug:\n",
    "            print(\"------------\")\n",
    "            print(article)\n",
    "\n",
    "        if \"rabatt\" in article:\n",
    "            # TODO: x = re.spltt(discount_pattern, article)\n",
    "            # articles.append([\"discount\", x[0], x[1]])\n",
    "            \n",
    "            # A line starting with \"Rabatt\" belongs to the line before.\n",
    "            if developing:\n",
    "                print(\"Found a discount line\")\n",
    "                print(article.split(\" \"))\n",
    "\n",
    "        elif \"antall\" in receipt_text:\n",
    "            # Do something TODO\n",
    "            if developing:\n",
    "                print(\"jadajada\")\n",
    "\n",
    "        elif \"artikler\" not in article:\n",
    "            x = re.split(price_pattern, article, 2)\n",
    "            \n",
    "            # Element 3, index 2, is always empty string\n",
    "            if len(x) == 3:\n",
    "                # actual article\n",
    "                item = x[0].strip()\n",
    "                price = x[1].strip()             \n",
    "                articles_querified.append([item, price])\n",
    "                if debug:\n",
    "                    print(\"len was 3\")\n",
    "                    print(\"Appending item '{}' with price '{}'. Full split is '{}'\".format(item, price, x))\n",
    "            else:\n",
    "                # Typically weight times price per kg.\n",
    "                if developing:\n",
    "                    print(\"Unparsable line: {}\".format(article))\n",
    "        else:\n",
    "            if developing:\n",
    "                print(\"Unparsable line 2: {}\".format(article))\n",
    "    return articles_querified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_item_category(item_name):\n",
    "    \"\"\" Search through similar items and reuse their category\n",
    "        Give it a category of 0 if it not seen before\n",
    "    \"\"\"\n",
    "    \n",
    "    query = datastore_client.query(kind=DATASTORE_KIND_CATEGORY_ASSIGNMENT)\n",
    "    #query.add_filter(\"item_name\", \"=\", item_name)\n",
    "    \n",
    "    # Create a filter on the key\n",
    "    first_key = datastore_client.key(DATASTORE_KIND_CATEGORY_ASSIGNMENT, item_name)\n",
    "    query.key_filter(first_key, '=')\n",
    "    \n",
    "    # Fetch only one result\n",
    "    q_result = query.fetch(limit=1)\n",
    "    \n",
    "    category_id = 0\n",
    "    for res in q_result:\n",
    "        category_id = res[\"cat_id\"]\n",
    "    \n",
    "    return category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_category(max_records):\n",
    "    \"\"\"\n",
    "    :param max_records (int): number of items to return\n",
    "    :return: a number of unclassified items from the category assignment registry\n",
    "    \"\"\"\n",
    "    \n",
    "    query = datastore_client.query(kind=DATASTORE_KIND_CATEGORY_ASSIGNMENT)\n",
    "    query.add_filter(\"cat_id\", \"=\", -1)\n",
    "    \n",
    "    # Fetch first X results\n",
    "    q_result = query.fetch(limit=max_records)\n",
    "    \n",
    "    return list(q_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_categories():\n",
    "    \"\"\"\n",
    "    Uploades categories based on excel file\n",
    "    \n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    filepath = \"../data/varekategorier.xlsx\"\n",
    "    cats = pd.read_excel(filepath)\n",
    "    \n",
    "    # Instantiates a client\n",
    "    datastore_client = datastore.Client(\n",
    "        credentials=credentials\n",
    "    )\n",
    "\n",
    "    # The kind for the new entity\n",
    "    kind = 'category'\n",
    "\n",
    "    for cat in cats.iterrows():\n",
    "\n",
    "        # The Cloud Datastore key for the new entity\n",
    "        category_id = str(cat[1][\"Varegruppe\"])\n",
    "        task_key = datastore_client.key(category_id)\n",
    "\n",
    "        # Prepares the new entity\n",
    "        task = datastore.Entity(key=task_key)\n",
    "        task['cat_name'] = cat[1][\"VAREGRUPPE NAVN\"]\n",
    "\n",
    "        if debug:\n",
    "            print(\"Writting to datastore:\",task)\n",
    "\n",
    "        # Saves the entity\n",
    "        datastore_client.put(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToDatastore(articles_querified, added_by, trans_datetime, receipt_id):\n",
    "    \"\"\"\n",
    "    :param articles_querified: list of text strings containing article text and price\n",
    "    :return: none\n",
    "    \"\"\"\n",
    "    \n",
    "    # Instantiates a client\n",
    "    datastore_client = datastore.Client(\n",
    "        credentials=credentials\n",
    "    )\n",
    "\n",
    "    # The kind for the new entity\n",
    "    kind = 'transaction'\n",
    "    \n",
    "    # Registered datetime\n",
    "    now = datetime.now()\n",
    "    \n",
    "    # Loop over all articles and insert one by one\n",
    "    for article in articles_querified:\n",
    "        #article = articles_querified[0]\n",
    "        item = article[0]\n",
    "        price = article[1]\n",
    "\n",
    "        category_id = fetch_item_category(item)\n",
    "        if debug:\n",
    "            print(\"Assignning category {} to item {}\".format(category_id, item))\n",
    "\n",
    "        if category_id == 0:\n",
    "            # TODO: THIS IS A NEW ITEM WE HAVE NOT SEEN BEFORE. ADD IT WITH -1 IN CATEGORY_MAPPING_ENTITIES\n",
    "            cat_task_key = datastore_client.key(DATASTORE_KIND_CATEGORY_ASSIGNMENT, item)\n",
    "            cat_task = datastore.Entity(key=cat_task_key)\n",
    "            cat_task[\"cat_id\"] = -1\n",
    "            datastore_client.put(cat_task)\n",
    "            print('Saved {}: {}'.format(cat_task.key.name, cat_task['cat_id']))\n",
    "            \n",
    "        # The Cloud Datastore key for the new entity. Creating with partial key\n",
    "        task_key = datastore_client.key(kind)\n",
    "\n",
    "        # Prepares the new entity\n",
    "        task = datastore.Entity(key=task_key)\n",
    "        task['added_by'] = added_by\n",
    "        task['cat_id'] = category_id\n",
    "        task['discount_amt'] = 0 # Missing\n",
    "        task['discount_type'] = 0 # Missing\n",
    "        task['item_id'] = 0 # Missing\n",
    "        task['item_name'] = item\n",
    "        task['price_gross'] = 0 # Missing\n",
    "        task['price_net'] = price\n",
    "        task['registered_datetime'] = now\n",
    "        task['trans_date'] = trans_datetime\n",
    "        task['receipt_id'] = receipt_id\n",
    "\n",
    "        if debug:\n",
    "            print(\"Writting to datastore:\",task)\n",
    "\n",
    "        # Saves the entity\n",
    "        datastore_client.put(task)\n",
    "\n",
    "        print('Saved {}: {}'.format(task.key.name, task['item_name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\NO007454\\Documents\\03. Internt\\24. Expense analyzer\\test_images\\IMG_1010.JPEG\"\n",
    "path = r\"C:\\Users\\NO007454\\Documents\\03. Internt\\24. Expense analyzer\\test_images\\IMG_1012.JPEG\"\n",
    "path = \"/Volumes/GoogleDrive/My Drive/00. My Documents/03. Internt/24. Expense analyzer/test_images/IMG_1010.JPEG\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = detect_text(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_items, receipt_id_and_datetime = article_lines_coop(response)\n",
    "receipt_lines = allocate_lines_coop(relevant_lines)\n",
    "actual_lines = lines_to_text(receipt_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a discount line\n",
      "['rabatt:', 'nok', '15.00', '(37.6%', 'av', '39.90)']\n",
      "Found a discount line\n",
      "['rabatt:', 'nok', '9.87', '(30%', 'av', '32.90)']\n",
      "Unparsable line: 0.080 kg 40.90 kr/kg\n",
      "Unparsable line: 0.242 kg 59.90 kr/kg\n",
      "Unparsable line: tomater ( 24.90)\n",
      "Unparsable line: 0.186 kg 24.90 kr/kg 7.98)\n",
      "Found a discount line\n",
      "['rabatt:', 'nok', '3.35', '(42%', 'av']\n",
      "Unparsable line 2: artikler ) 324.53\n"
     ]
    }
   ],
   "source": [
    "articles_querified = query_preparation(actual_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the receipt id and datetime before saving to datastore\n",
    "receipt_id = receipt_id_and_datetime.split(\" \")[0].strip()\n",
    "receipt_date = receipt_id_and_datetime.split(\" \")[1].strip()\n",
    "datetime_object = datetime.strptime(receipt_date, '%m.%d.%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved None: agurk stk\n",
      "Saved None: avokado modnet 2pk\n",
      "Saved None: bærepose mega\n",
      "Saved None: coop bomullspinner\n",
      "Saved None: coop kjøttdeig\n",
      "Saved None: coop maiskorn 3pk\n",
      "Saved None: gilde krydderskinke\n",
      "Saved None: hvitløk 100g\n",
      "Saved None: jozo kvernsalt 500g\n",
      "Saved None: lime kg\n",
      "Saved None: mack is.lit. 0.5l bx\n",
      "Saved None: pant\n",
      "Saved None: oep tortillas 8stk\n",
      "Saved None: q-lettrømme 300g\n",
      "Saved None: rød paprika\n",
      "Saved None: s.m sort pepper 22g\n",
      "Saved None: s.m taco sauce med.\n",
      "Saved None: spinatsalat vas.200g 22.90\n"
     ]
    }
   ],
   "source": [
    "writeToDatastore(articles_querified, \"testuser\", datetime_object, receipt_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_expense_analyzer",
   "language": "python",
   "name": "env_expense_analyzer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
